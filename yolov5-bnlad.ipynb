{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7588547,"sourceType":"datasetVersion","datasetId":4417083}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# save the working directory path for later use\n\nimport os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:07:12.488141Z","iopub.execute_input":"2024-02-12T15:07:12.488502Z","iopub.status.idle":"2024-02-12T15:07:12.500671Z","shell.execute_reply.started":"2024-02-12T15:07:12.488464Z","shell.execute_reply":"2024-02-12T15:07:12.499681Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"# clone project repository and install dependencies\n\n!git clone https://github.com/ultralytics/yolov5.git # clone\n%cd {HOME}/yolov5\n%pip install -r requirements.txt # install\n\nimport torch\nimport utils\ndisplay = utils.notebook_init()  # checks","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-12T15:07:13.966937Z","iopub.execute_input":"2024-02-12T15:07:13.967540Z","iopub.status.idle":"2024-02-12T15:07:41.168827Z","shell.execute_reply.started":"2024-02-12T15:07:13.967489Z","shell.execute_reply":"2024-02-12T15:07:41.167878Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"YOLOv5 üöÄ v7.0-284-g95ebf68f Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n","output_type":"stream"},{"name":"stdout","text":"Setup complete ‚úÖ (4 CPUs, 31.4 GB RAM, 5432.1/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"code","source":"# download pretrained weights\n\nfrom utils.downloads import attempt_download\n\np5 = ['n', 's', 'm', 'l', 'x']  # P5 models\ncls = [f'{x}-seg' for x in p5]  # segmentation models\n\nfor x in cls:\n    attempt_download(f'{HOME}/yolov5/weights/yolov5{x}.pt')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:07:44.878083Z","iopub.execute_input":"2024-02-12T15:07:44.878623Z","iopub.status.idle":"2024-02-12T15:07:59.537078Z","shell.execute_reply.started":"2024-02-12T15:07:44.878592Z","shell.execute_reply":"2024-02-12T15:07:59.536165Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n-seg.pt to /kaggle/working/yolov5/weights/yolov5n-seg.pt...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.11M/4.11M [00:01<00:00, 3.93MB/s]\n\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s-seg.pt to /kaggle/working/yolov5/weights/yolov5s-seg.pt...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.9M/14.9M [00:00<00:00, 321MB/s]\n\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m-seg.pt to /kaggle/working/yolov5/weights/yolov5m-seg.pt...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.4M/42.4M [00:00<00:00, 293MB/s]\n\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l-seg.pt to /kaggle/working/yolov5/weights/yolov5l-seg.pt...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.9M/91.9M [00:00<00:00, 276MB/s]\n\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x-seg.pt to /kaggle/working/yolov5/weights/yolov5x-seg.pt...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:08<00:00, 20.3MB/s] \n\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:08:08.678264Z","iopub.execute_input":"2024-02-12T15:08:08.678978Z","iopub.status.idle":"2024-02-12T15:08:09.633325Z","shell.execute_reply.started":"2024-02-12T15:08:08.678941Z","shell.execute_reply":"2024-02-12T15:08:09.632178Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"CITATION.cff\t benchmarks.py\texport.py\t  segment\t  weights\nCONTRIBUTING.md  classify\thubconf.py\t  train.py\nLICENSE\t\t data\t\tmodels\t\t  tutorial.ipynb\nREADME.md\t data.yaml\tpyproject.toml\t  utils\nREADME.zh-CN.md  detect.py\trequirements.txt  val.py\n","output_type":"stream"}]},{"cell_type":"code","source":"file_content = \"\"\"\nnames:\n- newspaper\n- image\n- news\n- paragraph\n- table\n- text_box\n\nnc: 6\ntrain: /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train/images\nval: /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/val/images\n\n\"\"\"\n\nwith open(\"data.yaml\", mode=\"w\") as f:\n    f.write(file_content)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:08:03.869086Z","iopub.execute_input":"2024-02-12T15:08:03.869468Z","iopub.status.idle":"2024-02-12T15:08:03.875292Z","shell.execute_reply.started":"2024-02-12T15:08:03.869437Z","shell.execute_reply":"2024-02-12T15:08:03.874342Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:09:50.889060Z","iopub.execute_input":"2024-02-12T15:09:50.889879Z","iopub.status.idle":"2024-02-12T15:09:51.830697Z","shell.execute_reply.started":"2024-02-12T15:09:50.889839Z","shell.execute_reply":"2024-02-12T15:09:51.829644Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5\n","output_type":"stream"}]},{"cell_type":"code","source":"#%cd {HOME}/yolov5 \n!python segment/train.py --img 320 --batch 32 --epochs 5 --data /kaggle/working/yolov5/data.yaml --weights yolov5s-seg.pt --name custom-dataset\n#display.Image(filename=f'{HOME}/yolov5/runs/train-seg/custom-dataset/results.png', width=1200)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:15:42.374749Z","iopub.execute_input":"2024-02-12T15:15:42.375133Z","iopub.status.idle":"2024-02-12T15:38:03.684531Z","shell.execute_reply.started":"2024-02-12T15:15:42.375100Z","shell.execute_reply":"2024-02-12T15:38:03.683216Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"2024-02-12 15:15:49.878883: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-12 15:15:49.878939: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-12 15:15:49.880390: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1msegment/train: \u001b[0mweights=yolov5s-seg.pt, cfg=, data=/kaggle/working/yolov5/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train-seg, name=custom-dataset, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, mask_ratio=4, no_overlap=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\nWARNING ‚ö†Ô∏è invalid check_version(None, >=3.3) requested, please check values.\nYOLOv5 üöÄ v7.0-284-g95ebf68f Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-seg', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=6\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1    415555  models.yolo.Segment                     [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], 32, 128, [128, 256, 512]]\nModel summary: 225 layers, 7421699 parameters, 7421699 gradients, 26.0 GFLOPs\n\nTransferred 361/367 items from yolov5s-seg.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 60 weight(decay=0.0), 63 weight(decay=0.0005), 63 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train/label\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train/images/image_10_png.rf.3b1063be1490ff55b8ecf1905d6ce385.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train/images/image_175_png.rf.9bca9cfe990cac2c19def788c7f86e6a.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train/images/image_24_png.rf.7e276f3ca253e7d7e9234ccd58149e03.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train/images/image_68_png.rf.428f12fbf8a0008b0e2f74f0ff11bc79.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train is not writeable: [Errno 30] Read-only file system: '/kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/train/labels.cache.npy'\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/val/labels...\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/val is not writeable: [Errno 30] Read-only file system: '/kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/val/labels.cache.npy'\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.20 anchors/target, 0.668 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ‚ö†Ô∏è Extremely small objects found: 33692 of 123527 labels are <3 pixels in size\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 122801 points...\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7163: 100%|‚ñà‚ñà‚ñà‚ñà\u001b[0m\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9970 best possible recall, 4.45 anchors past thr\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=320, metric_all=0.302/0.714-mean/best, past_thr=0.484-mean: 5,2, 12,3, 25,3, 24,7, 29,13, 54,7, 34,24, 30,55, 72,65\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)\nPlotting labels to runs/train-seg/custom-dataset2/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 320 train, 320 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/train-seg/custom-dataset2\u001b[0m\nStarting training for 5 epochs...\n\n      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n        0/4      11.6G     0.1488     0.1341     0.1128    0.05309       2411   \n                 Class     Images  Instances      Box(P          R      mAP50  mWARNING ‚ö†Ô∏è NMS time limit 3.700s exceeded\n                 Class     Images  Instances      Box(P          R      mAP50  mWARNING ‚ö†Ô∏è NMS time limit 1.950s exceeded\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418    0.00268    0.00459    0.00139   0.000315    0.00892      0.011    0.00476    0.00138\n\n      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n        1/4      12.8G     0.1322    0.09699     0.1661    0.03964       3647   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418     0.0657     0.0603     0.0396      0.011     0.0464      0.048     0.0296     0.0096\n\n      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n        2/4      12.8G     0.1279    0.09527     0.1833    0.03391       2641   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418     0.0767      0.115     0.0634     0.0187     0.0565     0.0765     0.0444     0.0142\n\n      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n        3/4      12.8G     0.1261    0.09389     0.1891    0.03153       3052   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418     0.0962      0.155     0.0805     0.0252     0.0727      0.105     0.0607     0.0197\n\n      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n        4/4      12.8G      0.124    0.09183     0.1951    0.03014       3389   \n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418      0.352      0.156      0.106     0.0365      0.317      0.106     0.0817     0.0285\n\n5 epochs completed in 0.313 hours.\nOptimizer stripped from runs/train-seg/custom-dataset2/weights/last.pt, 15.1MB\nOptimizer stripped from runs/train-seg/custom-dataset2/weights/best.pt, 15.1MB\n\nValidating runs/train-seg/custom-dataset2/weights/best.pt...\nFusing layers... \nModel summary: 165 layers, 7411907 parameters, 0 gradients, 25.7 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418      0.351      0.157      0.106     0.0366      0.316      0.107      0.082     0.0285\n             newspaper         93        998      0.332      0.189      0.239     0.0963      0.315      0.184      0.232     0.0907\n                 image         93       1167      0.182      0.266      0.128     0.0414   0.000569   0.000857   0.000187   7.28e-05\n                  news         93       4715      0.139      0.278      0.119     0.0321      0.135      0.278      0.115     0.0311\n             paragraph         93         70          1          0          0          0          1          0          0          0\n                 table         93      11468      0.103     0.0525     0.0453     0.0134       0.13     0.0691     0.0627     0.0208\nResults saved to \u001b[1mruns/train-seg/custom-dataset2\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd {HOME}/yolov5\n!python segment/val.py --weights /kaggle/working/yolov5/runs/train-seg/custom-dataset2/weights/best.pt --data /kaggle/working/yolov5/data.yaml --img 320  --name custom-dataset-val >> output.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:49:34.424377Z","iopub.execute_input":"2024-02-12T15:49:34.425031Z","iopub.status.idle":"2024-02-12T15:51:45.350684Z","shell.execute_reply.started":"2024-02-12T15:49:34.425002Z","shell.execute_reply":"2024-02-12T15:51:45.349471Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5\n\u001b[34m\u001b[1msegment/val: \u001b[0mdata=/kaggle/working/yolov5/data.yaml, weights=['/kaggle/working/yolov5/runs/train-seg/custom-dataset2/weights/best.pt'], batch_size=32, imgsz=320, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val-seg, name=custom-dataset-val, exist_ok=False, half=False, dnn=False\nYOLOv5 üöÄ v7.0-284-g95ebf68f Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 165 layers, 7411907 parameters, 0 gradients, 25.7 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/val/labels...\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/val is not writeable: [Errno 30] Read-only file system: '/kaggle/input/bnlad-yolo/kaggle/working/yolov5_split/val/labels.cache.npy'\n                 Class     Images  Instances      Box(P          R      mAP50  mWARNING ‚ö†Ô∏è NMS time limit 1.950s exceeded\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418      0.354      0.157      0.106     0.0364      0.324      0.144      0.091     0.0325\n             newspaper         93        998      0.341      0.193      0.237     0.0949      0.288      0.187      0.222     0.0914\n                 image         93       1167      0.184      0.267      0.133     0.0422      0.098      0.176     0.0654     0.0184\n                  news         93       4715       0.14      0.271      0.117     0.0315      0.123      0.282      0.109      0.031\n             paragraph         93         70          1          0          0          0          1          0          0          0\n                 table         93      11468      0.105     0.0526     0.0452     0.0132      0.111     0.0725     0.0584     0.0217\nSpeed: 67.6ms pre-process, 16.5ms inference, 52.6ms NMS per image at shape (32, 3, 320, 320)\nResults saved to \u001b[1mruns/val-seg/custom-dataset-val2\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:42:29.543713Z","iopub.execute_input":"2024-02-12T15:42:29.544029Z","iopub.status.idle":"2024-02-12T15:42:30.577223Z","shell.execute_reply.started":"2024-02-12T15:42:29.544001Z","shell.execute_reply":"2024-02-12T15:42:30.575968Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"CITATION.cff\t benchmarks.py\thubconf.py\t  train.py\nCONTRIBUTING.md  classify\tmodels\t\t  tutorial.ipynb\nLICENSE\t\t data\t\tpyproject.toml\t  utils\nREADME.md\t data.yaml\trequirements.txt  val.py\nREADME.zh-CN.md  detect.py\truns\t\t  weights\n__pycache__\t export.py\tsegment\t\t  yolov5s-seg.pt\n","output_type":"stream"}]},{"cell_type":"code","source":" Class     Images  Instances      Box(P          R      mAP50  m\n                   all         93      18418      0.354      0.157      0.106     0.0364      0.324      0.144      0.091     0.0325\n             newspaper         93        998      0.341      0.193      0.237     0.0949      0.288      0.187      0.222     0.0914\n                 image         93       1167      0.184      0.267      0.133     0.0422      0.098      0.176     0.0654     0.0184\n                  news         93       4715       0.14      0.271      0.117     0.0315      0.123      0.282      0.109      0.031\n             paragraph         93         70          1          0          0          0          1          0          0          0\n                 table         93      11468      0.105     0.0526     0.0452     0.0132      0.111     0.0725     0.0584     0.0217","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/working/yolov5/runs/train-seg/custom-dataset2/results.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:47:07.236793Z","iopub.execute_input":"2024-02-12T15:47:07.237165Z","iopub.status.idle":"2024-02-12T15:47:07.271182Z","shell.execute_reply.started":"2024-02-12T15:47:07.237137Z","shell.execute_reply":"2024-02-12T15:47:07.270120Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"            epoch  train/box_loss  train/seg_loss  train/obj_loss  \\\n0               0         0.14884        0.134070         0.11284   \n1               1         0.13219        0.096992         0.16608   \n2               2         0.12791        0.095266         0.18332   \n3               3         0.12605        0.093886         0.18912   \n4               4         0.12404        0.091832         0.19510   \n5               5         0.35128        0.157110         0.10650   \n\n   train/cls_loss  ...    val/obj_loss    val/cls_loss           x/lr0  \\\n0        0.053089  ...         0.10948        0.046129        0.079300   \n1        0.039640  ...         0.12659        0.034438        0.056769   \n2        0.033909  ...         0.13732        0.030737        0.033288   \n3        0.031529  ...         0.14340        0.027821        0.008857   \n4        0.030144  ...         0.14993        0.026424        0.002080   \n5        0.036632  ...             NaN             NaN             NaN   \n\n            x/lr1           x/lr2  \n0        0.002300        0.002300  \n1        0.003769        0.003769  \n2        0.004288        0.004288  \n3        0.003857        0.003857  \n4        0.002080        0.002080  \n5             NaN             NaN  \n\n[6 rows x 20 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>train/box_loss</th>\n      <th>train/seg_loss</th>\n      <th>train/obj_loss</th>\n      <th>train/cls_loss</th>\n      <th>...</th>\n      <th>val/obj_loss</th>\n      <th>val/cls_loss</th>\n      <th>x/lr0</th>\n      <th>x/lr1</th>\n      <th>x/lr2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.14884</td>\n      <td>0.134070</td>\n      <td>0.11284</td>\n      <td>0.053089</td>\n      <td>...</td>\n      <td>0.10948</td>\n      <td>0.046129</td>\n      <td>0.079300</td>\n      <td>0.002300</td>\n      <td>0.002300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.13219</td>\n      <td>0.096992</td>\n      <td>0.16608</td>\n      <td>0.039640</td>\n      <td>...</td>\n      <td>0.12659</td>\n      <td>0.034438</td>\n      <td>0.056769</td>\n      <td>0.003769</td>\n      <td>0.003769</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.12791</td>\n      <td>0.095266</td>\n      <td>0.18332</td>\n      <td>0.033909</td>\n      <td>...</td>\n      <td>0.13732</td>\n      <td>0.030737</td>\n      <td>0.033288</td>\n      <td>0.004288</td>\n      <td>0.004288</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.12605</td>\n      <td>0.093886</td>\n      <td>0.18912</td>\n      <td>0.031529</td>\n      <td>...</td>\n      <td>0.14340</td>\n      <td>0.027821</td>\n      <td>0.008857</td>\n      <td>0.003857</td>\n      <td>0.003857</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.12404</td>\n      <td>0.091832</td>\n      <td>0.19510</td>\n      <td>0.030144</td>\n      <td>...</td>\n      <td>0.14993</td>\n      <td>0.026424</td>\n      <td>0.002080</td>\n      <td>0.002080</td>\n      <td>0.002080</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.35128</td>\n      <td>0.157110</td>\n      <td>0.10650</td>\n      <td>0.036632</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows √ó 20 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}