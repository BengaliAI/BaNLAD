{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8766707,"sourceType":"datasetVersion","datasetId":5263377}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\nimport sys, os, distutils.core\n# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n!git clone 'https://github.com/facebookresearch/detectron2'\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\nprint(' '.join([f\"'{x}'\" for x in dist.install_requires]))\nprint(dist)\nsys.path.insert(0, os.path.abspath('./detectron2'))","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:35:56.926786Z","iopub.execute_input":"2024-06-26T09:35:56.927153Z","iopub.status.idle":"2024-06-26T09:36:23.788952Z","shell.execute_reply.started":"2024-06-26T09:35:56.927124Z","shell.execute_reply":"2024-06-26T09:36:23.787700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.memory import retry_if_cuda_oom\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.modeling import build_model\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nimport detectron2.data.transforms as T\nfrom detectron2.data import detection_utils as utils\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader, DatasetMapper\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.structures import BoxMode\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2 import model_zoo\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm  # progress bar\nimport matplotlib.pyplot as plt\nimport json\nimport cv2\nimport copy\nfrom typing import Optional\n\n\nfrom IPython.display import FileLink\nimport sys\n# torch\nimport torch\n\nimport gc\n\nimport warnings\n# Ignore \"future\" warnings and Data-Frame-Slicing warnings.\nwarnings.filterwarnings('ignore')\n\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:23.791300Z","iopub.execute_input":"2024-06-26T09:36:23.792526Z","iopub.status.idle":"2024-06-26T09:36:26.359438Z","shell.execute_reply.started":"2024-06-26T09:36:23.792484Z","shell.execute_reply":"2024-06-26T09:36:26.358527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Data load\ntorch.cuda.empty_cache()\nfrom pathlib import Path\n\nTRAIN_IMG_DIR = Path(\"/kaggle/input/banlad2599-bangla-newspaper-layout-dataset/All_Crumpled_Images\")\n\nTRAIN_COCO_PATH=Path(\"/kaggle/input/banlad2599-bangla-newspaper-layout-dataset/merged_coco.json\")\n\n# Training output directory\nOUTPUT_DIR = Path(\"./output\")\nOUTPUT_MODEL = OUTPUT_DIR/\"model_final.pth\"\n\n# Path to your pretrained model weights\nPRETRAINED_PATH = Path(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:26.360483Z","iopub.execute_input":"2024-06-26T09:36:26.360907Z","iopub.status.idle":"2024-06-26T09:36:26.366119Z","shell.execute_reply.started":"2024-06-26T09:36:26.360867Z","shell.execute_reply":"2024-06-26T09:36:26.365135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Coco Annotation\nfrom pycocotools.coco import COCO\n\nwith TRAIN_COCO_PATH.open() as f:\n    train_dict = json.load(f)\n\ntrain_coco_labels=COCO(annotation_file=TRAIN_COCO_PATH)\n\nprint(\"#### LABELS AND METADATA LOADED ####\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:26.368664Z","iopub.execute_input":"2024-06-26T09:36:26.369021Z","iopub.status.idle":"2024-06-26T09:36:41.533951Z","shell.execute_reply.started":"2024-06-26T09:36:26.368991Z","shell.execute_reply":"2024-06-26T09:36:41.533018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Decisions\n\nfrom datetime import datetime\n\n# if False, model is set to `PRETRAINED_PATH` model\nis_train = True\n\n# if True, evaluate on validation dataset\nis_evaluate = False\n\n# if True, run inference on test dataset\nis_inference = True\n\n# if True and `is_train` == True, `PRETRAINED_PATH` model is trained further\nis_resume_training = False\n\n# Perform augmentation\nis_augment = True\n\nSEED = 1234\n\n# Model path based on Decisions\nMODEL_PATH = OUTPUT_MODEL if is_train else PRETRAINED_PATH","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:41.535035Z","iopub.execute_input":"2024-06-26T09:36:41.535311Z","iopub.status.idle":"2024-06-26T09:36:41.540643Z","shell.execute_reply.started":"2024-06-26T09:36:41.535286Z","shell.execute_reply":"2024-06-26T09:36:41.539719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"There are \" + str(len(train_dict['categories'])) + \" categories.\\n\")\n# print(\"There are \" + str(len(test_dict['images']) + len(train_dict['images'])) + \" images in the dataset.\")\nprint(\"There are \" + str(len(train_dict['images'])) + \" images in the train set.\")\n# print(\"There are \" + str(len(test_dict['images'])) + \" images in the test set.\\n\")\nprint(\"There are \" + str(len(train_dict['annotations'])) + \" annotations in the train set.\\n\")\n\nprint(\"We will focus on mainly categories, images and annotations.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:41.541840Z","iopub.execute_input":"2024-06-26T09:36:41.542816Z","iopub.status.idle":"2024-06-26T09:36:41.575391Z","shell.execute_reply.started":"2024-06-26T09:36:41.542781Z","shell.execute_reply":"2024-06-26T09:36:41.574471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def organize_coco_data(data_dict: dict) -> tuple[list[str], list[dict], list[dict]]:\n    thing_classes: list[str] = []\n\n    # Map Category Names to IDs\n    for cat in data_dict['categories']:\n        thing_classes.append(cat['name'])\n\n    # Images\n    images_metadata: list[dict] = data_dict['images']\n\n    # Convert COCO annotations to detectron2 annotations format\n    data_annotations = []\n    for ann in data_dict['annotations']:\n        # coco format -> detectron2 format\n        annot_obj = {\n            # Annotation ID\n            \"id\": ann['id'],\n\n            # Segmentation Polygon (x, y) coordinnates\n            \"gt_masks\": ann['segmentation'],\n\n            # Image ID for this annotation (Which image does this annotation belong to?)\n            \"image_id\": ann['image_id'],\n\n            # Category Label (0: paragraph, 1: text box, 2: image, 3: table)\n            \"category_id\": ann['category_id'],\n\n            \"x_min\": ann['bbox'][0],  # left\n            \"y_min\": ann['bbox'][1],  # top\n            \"x_max\": ann['bbox'][0] + ann['bbox'][2],  # left+width\n            \"y_max\": ann['bbox'][1] + ann['bbox'][3]  # top+height\n        }\n        data_annotations.append(annot_obj)\n\n    return thing_classes, images_metadata, data_annotations","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:41.576400Z","iopub.execute_input":"2024-06-26T09:36:41.576631Z","iopub.status.idle":"2024-06-26T09:36:41.605597Z","shell.execute_reply.started":"2024-06-26T09:36:41.576611Z","shell.execute_reply":"2024-06-26T09:36:41.604736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thing_classes, images_metadata, data_annotations = organize_coco_data(train_dict)\n\n# thing_classes_test, images_metadata_test, _ = organize_coco_data(test_dict)\n\nprint(thing_classes)\n# thing_classes = [cls for cls in thing_classes if cls != 'newspaper']\n\nprint(len(thing_classes))","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:41.606400Z","iopub.execute_input":"2024-06-26T09:36:41.606664Z","iopub.status.idle":"2024-06-26T09:36:42.803456Z","shell.execute_reply.started":"2024-06-26T09:36:41.606633Z","shell.execute_reply":"2024-06-26T09:36:42.802539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_metadata = pd.DataFrame(images_metadata)\ntrain_metadata = train_metadata[['id', 'file_name', 'width', 'height']]\ntrain_metadata = train_metadata.rename(columns={\"id\": \"image_id\"})\nprint(\"train_metadata size=\", len(train_metadata))\ntrain_metadata.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:53.716828Z","iopub.execute_input":"2024-06-26T09:36:53.717656Z","iopub.status.idle":"2024-06-26T09:36:53.738879Z","shell.execute_reply.started":"2024-06-26T09:36:53.717623Z","shell.execute_reply":"2024-06-26T09:36:53.737801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_annot_df = pd.DataFrame(data_annotations)\nprint(\"train_annot_df size=\", len(train_annot_df))\ntrain_annot_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:55.276777Z","iopub.execute_input":"2024-06-26T09:36:55.277134Z","iopub.status.idle":"2024-06-26T09:36:57.695360Z","shell.execute_reply.started":"2024-06-26T09:36:55.277107Z","shell.execute_reply":"2024-06-26T09:36:57.694482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming the provided data is stored in a DataFrame named df\n# Replace df with the actual variable name if different\n\n# Count occurrences of each category ID\ncategory_counts = train_annot_df['category_id'].value_counts()\n\n# Print the result\nprint(\"Category ID\\tNumber of Instances\")\nfor category_id, count in category_counts.items():\n    print(f\"{category_id}\\t\\t{count}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:36:57.697333Z","iopub.execute_input":"2024-06-26T09:36:57.697695Z","iopub.status.idle":"2024-06-26T09:36:57.709026Z","shell.execute_reply.started":"2024-06-26T09:36:57.697663Z","shell.execute_reply":"2024-06-26T09:36:57.708158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Formatting Data for detectron2\ndef convert_coco_to_detectron2_format(\n    imgdir: Path,\n    metadata_df: pd.DataFrame,\n    annot_df: Optional[pd.DataFrame] = None,\n    target_indices: Optional[np.ndarray] = None,\n):\n\n    dataset_dicts = []\n    for _, train_meta_row in tqdm(metadata_df.iterrows(), total=len(metadata_df)):\n        # Iterate over each image\n        image_id, filename, width, height = train_meta_row.values\n\n        annotations = []\n        \n        # If train/validation data, then there will be annotations\n        if annot_df is not None:\n            for _, ann in annot_df.query(\"image_id == @image_id\").iterrows():\n                # Get annotations of current iteration's image\n                class_id = ann[\"category_id\"]\n                gt_masks = ann[\"gt_masks\"]\n                bbox_resized = [\n                    float(ann[\"x_min\"]),\n                    float(ann[\"y_min\"]),\n                    float(ann[\"x_max\"]),\n                    float(ann[\"y_max\"]),\n                ]\n\n                annotation = {\n                    \"bbox\": bbox_resized,\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"segmentation\": gt_masks,\n                    \"category_id\": class_id,\n                }\n\n                annotations.append(annotation)\n        # coco format -> detectron2 format dict\n        record = {\n            \"file_name\": str(imgdir/filename),\n            \"image_id\": image_id,\n            \"width\": width,\n            \"height\": height,\n            \"annotations\": annotations\n        }\n\n        dataset_dicts.append(record)\n\n    if target_indices is not None:\n        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n\n    return dataset_dicts","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:13.834496Z","iopub.execute_input":"2024-06-26T09:37:13.834849Z","iopub.status.idle":"2024-06-26T09:37:13.845381Z","shell.execute_reply.started":"2024-06-26T09:37:13.834821Z","shell.execute_reply":"2024-06-26T09:37:13.844416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_mapper(dataset_dict):\n    dataset_dict = copy.deepcopy(dataset_dict)\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n\n    transform_list = [T.RandomBrightness(0.9, 1.0),\n                      T.RandomContrast(0.8,1.4),\n#                       T.RandomFlip(prob=0.5, horizontal=False, vertical=True)\n                        T.Resize((800,800))\n                      #T.RandomFlip(prob=0.5, horizontal=True, vertical=False)\n                      ]\n    image, transforms = T.apply_transform_gens(transform_list, image)\n\n    dataset_dict[\"image\"] = torch.as_tensor(\n        image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n\n    return dataset_dict","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:14.270159Z","iopub.execute_input":"2024-06-26T09:37:14.270515Z","iopub.status.idle":"2024-06-26T09:37:14.277986Z","shell.execute_reply.started":"2024-06-26T09:37:14.270487Z","shell.execute_reply":"2024-06-26T09:37:14.277050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AugTrainer(DefaultTrainer):\n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg, mapper=custom_mapper)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:14.759804Z","iopub.execute_input":"2024-06-26T09:37:14.760506Z","iopub.status.idle":"2024-06-26T09:37:14.764976Z","shell.execute_reply.started":"2024-06-26T09:37:14.760476Z","shell.execute_reply":"2024-06-26T09:37:14.764038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_SPLIT = 0.95","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:29.062118Z","iopub.execute_input":"2024-06-26T09:37:29.062727Z","iopub.status.idle":"2024-06-26T09:37:29.066527Z","shell.execute_reply.started":"2024-06-26T09:37:29.062698Z","shell.execute_reply":"2024-06-26T09:37:29.065658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_dataset = len(train_metadata)\nn_train = int(n_dataset * TRAIN_SPLIT)\nprint(\"n_dataset\", n_dataset, \"n_train\", n_train, \"n_val\", n_dataset-n_train)\n\nnp.random.seed(1234)\n\ninds = np.random.permutation(n_dataset)\ntrain_inds, valid_inds = inds[:n_train], inds[n_train:]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:32.819711Z","iopub.execute_input":"2024-06-26T09:37:32.820494Z","iopub.status.idle":"2024-06-26T09:37:32.828201Z","shell.execute_reply.started":"2024-06-26T09:37:32.820463Z","shell.execute_reply":"2024-06-26T09:37:32.827053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DatasetCatalog.clear()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:34.335134Z","iopub.execute_input":"2024-06-26T09:37:34.335762Z","iopub.status.idle":"2024-06-26T09:37:34.339774Z","shell.execute_reply.started":"2024-06-26T09:37:34.335733Z","shell.execute_reply":"2024-06-26T09:37:34.338836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Registering and Loading Data for detectron2\nDATA_REGISTER_TRAINING = \"badlad_train\"\nDATA_REGISTER_VALID    = \"badlad_valid\"\nDATA_REGISTER_TEST     = \"badlad_test\"","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:34.797507Z","iopub.execute_input":"2024-06-26T09:37:34.797864Z","iopub.status.idle":"2024-06-26T09:37:34.802093Z","shell.execute_reply.started":"2024-06-26T09:37:34.797835Z","shell.execute_reply":"2024-06-26T09:37:34.801214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Register Training data\nif is_train:\n    DatasetCatalog.register(\n        DATA_REGISTER_TRAINING,\n        lambda: convert_coco_to_detectron2_format(\n            TRAIN_IMG_DIR,\n            train_metadata,\n            train_annot_df,\n            target_indices=train_inds,\n        ),\n    )\n\n    # Set Training data categories\n    MetadataCatalog.get(DATA_REGISTER_TRAINING).set(thing_classes=thing_classes)\n\n    dataset_dicts_train = DatasetCatalog.get(DATA_REGISTER_TRAINING)\n    metadata_dicts_train = MetadataCatalog.get(DATA_REGISTER_TRAINING)\n\n    print(\"dicts training size=\", len(dataset_dicts_train))\n    print(\"################\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:37:35.368263Z","iopub.execute_input":"2024-06-26T09:37:35.368629Z","iopub.status.idle":"2024-06-26T09:38:41.768161Z","shell.execute_reply.started":"2024-06-26T09:37:35.368599Z","shell.execute_reply":"2024-06-26T09:38:41.767264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Register Validation data\nif is_train or is_evaluate:\n    DatasetCatalog.register(\n        DATA_REGISTER_VALID,\n        lambda: convert_coco_to_detectron2_format(\n            TRAIN_IMG_DIR,\n            train_metadata,\n            train_annot_df,\n            target_indices=valid_inds,\n        ),\n    )\n\n    # Set Validation data categories\n    MetadataCatalog.get(DATA_REGISTER_VALID).set(thing_classes=thing_classes)\n\n    dataset_dicts_valid = DatasetCatalog.get(DATA_REGISTER_VALID)\n    metadata_dicts_valid = MetadataCatalog.get(DATA_REGISTER_VALID)\n\n    print(\"dicts valid size=\", len(dataset_dicts_valid))\n    print(\"################\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:38:41.770128Z","iopub.execute_input":"2024-06-26T09:38:41.770669Z","iopub.status.idle":"2024-06-26T09:39:49.011575Z","shell.execute_reply.started":"2024-06-26T09:38:41.770633Z","shell.execute_reply":"2024-06-26T09:39:49.010743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install gdown\n!gdown 1XsjWuZjnQFxrYu9hgWJ1_qIf22q9P2EX","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:39:49.013138Z","iopub.execute_input":"2024-06-26T09:39:49.013881Z","iopub.status.idle":"2024-06-26T09:39:50.020346Z","shell.execute_reply.started":"2024-06-26T09:39:49.013846Z","shell.execute_reply":"2024-06-26T09:39:50.019324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRETRAINED_PATH=Path(\"/kaggle/working/model_final.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:39:50.023091Z","iopub.execute_input":"2024-06-26T09:39:50.023417Z","iopub.status.idle":"2024-06-26T09:39:50.028253Z","shell.execute_reply.started":"2024-06-26T09:39:50.023388Z","shell.execute_reply":"2024-06-26T09:39:50.027326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_train:\n    cfg = get_cfg()\n\n    # config_name = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n    config_name = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n\n    cfg.merge_from_file(model_zoo.get_config_file(config_name))\n\n    cfg.DATASETS.TRAIN = (DATA_REGISTER_TRAINING,)\n#     cfg.DATASETS.TEST = (DATA_REGISTER_VALID,)\n\n    # to evaluate during training, you have to implement `build_evaluator()` method of the trainer.\n    # https://github.com/facebookresearch/detectron2/blob/94113be6e12db36b8c7601e13747587f19ec92fe/detectron2/engine/defaults.py#L561\n    # cfg.TEST.EVAL_PERIOD = 500\n    cfg.DATALOADER.NUM_WORKERS = 2\n\n    # cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n    if (is_resume_training):\n        print(\"#### SETTING PRETRAINED WEIGHTS TO RESUME TRAINING ####\")\n        cfg.MODEL.WEIGHTS = str(PRETRAINED_PATH)\n    else:\n        print(\"#### TRAINING MODEL FROM SCRATCH ####\")\n\n    cfg.SOLVER.AMP.ENABLED = True\n    cfg.SOLVER.IMS_PER_BATCH = 4\n    cfg.SOLVER.BASE_LR = 0.001\n\n    cfg.SOLVER.WARMUP_ITERS = 5\n\n    # Maximum number of iterations\n    cfg.SOLVER.MAX_ITER = 30000\n\n    # cfg.SOLVER.STEPS = (500, 1000) # must be less than MAX_ITER\n\n    cfg.SOLVER.GAMMA = 0.09\n    # Small value == Frequent save need a lot of storage.\n    cfg.SOLVER.CHECKPOINT_PERIOD = 10000\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n\n    # Create Output Directory\n    cfg.OUTPUT_DIR = str(OUTPUT_DIR)\n    print(\"creating cfg.OUTPUT_DIR -> \", cfg.OUTPUT_DIR)\n    OUTPUT_DIR.mkdir(exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:39:50.029486Z","iopub.execute_input":"2024-06-26T09:39:50.029742Z","iopub.status.idle":"2024-06-26T09:39:50.060782Z","shell.execute_reply.started":"2024-06-26T09:39:50.029719Z","shell.execute_reply":"2024-06-26T09:39:50.059998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_train:\n    trainer = AugTrainer(cfg)\n        \n    trainer.resume_or_load(resume=is_resume_training)\n\n    trainer.train()\n    \n    print(\"#### TRAINING COMPLETE ####\")\n    _ = trainer.model.train(False)  # turn off training\n    \n    FileLink(str(OUTPUT_MODEL))","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:39:50.061987Z","iopub.execute_input":"2024-06-26T09:39:50.062336Z","iopub.status.idle":"2024-06-26T20:34:40.761522Z","shell.execute_reply.started":"2024-06-26T09:39:50.062307Z","shell.execute_reply":"2024-06-26T20:34:40.759638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install gdown\n# !gdown 1ulMedVIsY-WjaH3_DLnipfMngNx8JT4v\n!gdown 16jl3AXYa91c3OXr3EoSV-ymQJ4ZpGhSx","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:36:11.084557Z","iopub.execute_input":"2024-06-26T08:36:11.084900Z","iopub.status.idle":"2024-06-26T08:36:14.043024Z","shell.execute_reply.started":"2024-06-26T08:36:11.084871Z","shell.execute_reply":"2024-06-26T08:36:14.041632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inf_cfg = get_cfg()\n\nconfig_name = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n\ninf_cfg.merge_from_file(model_zoo.get_config_file(config_name))\ninf_cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\ninf_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\ninf_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ninf_cfg.MODEL.DEVICE = \"cuda\"\n\ninf_cfg.DATALOADER.NUM_WORKERS = 2  # lower this if CUDA overflow occurs\ninf_cfg.MODEL.WEIGHTS = str(\"/kaggle/working/output/model_final.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:35:59.658750Z","iopub.execute_input":"2024-06-26T20:35:59.659119Z","iopub.status.idle":"2024-06-26T20:35:59.681671Z","shell.execute_reply.started":"2024-06-26T20:35:59.659090Z","shell.execute_reply":"2024-06-26T20:35:59.680913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 1  # lower if CUDA overflow occurs\ntest_loader = build_detection_test_loader(inf_cfg, DATA_REGISTER_VALID, batch_size=BATCH)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:36:01.949386Z","iopub.execute_input":"2024-06-26T20:36:01.949745Z","iopub.status.idle":"2024-06-26T20:37:05.259973Z","shell.execute_reply.started":"2024-06-26T20:36:01.949716Z","shell.execute_reply":"2024-06-26T20:37:05.259068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test Data Inference\n#Building Inference Model\n\ndef rebuild_model():\n    model = build_model(inf_cfg)\n    _ = DetectionCheckpointer(model).load(inf_cfg.MODEL.WEIGHTS)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:37:09.047344Z","iopub.execute_input":"2024-06-26T20:37:09.047677Z","iopub.status.idle":"2024-06-26T20:37:09.052651Z","shell.execute_reply.started":"2024-06-26T20:37:09.047646Z","shell.execute_reply":"2024-06-26T20:37:09.051663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = rebuild_model()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:37:10.074736Z","iopub.execute_input":"2024-06-26T20:37:10.075026Z","iopub.status.idle":"2024-06-26T20:37:11.249846Z","shell.execute_reply.started":"2024-06-26T20:37:10.075002Z","shell.execute_reply":"2024-06-26T20:37:11.248692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model_from_cfg(cfg):\n    model = build_model(cfg)\n    _ = DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:37:13.074677Z","iopub.execute_input":"2024-06-26T20:37:13.075360Z","iopub.status.idle":"2024-06-26T20:37:13.080068Z","shell.execute_reply.started":"2024-06-26T20:37:13.075328Z","shell.execute_reply":"2024-06-26T20:37:13.078944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"### EVALUATING ON VALIDATION DATA ####\")\n\n# trained model weights\nevaluation_model = build_model_from_cfg(inf_cfg)\n\nevaluator = COCOEvaluator(\n    DATA_REGISTER_VALID, inf_cfg, False, output_dir=inf_cfg.OUTPUT_DIR, use_fast_impl=True\n)\n\ntest_loader = build_detection_test_loader(inf_cfg, DATA_REGISTER_VALID,mapper=custom_mapper)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:37:19.747029Z","iopub.execute_input":"2024-06-26T20:37:19.747687Z","iopub.status.idle":"2024-06-26T20:39:31.413746Z","shell.execute_reply.started":"2024-06-26T20:37:19.747654Z","shell.execute_reply":"2024-06-26T20:39:31.412848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_df = pd.read_json(\n        \"/kaggle/working/output/metrics.json\", orient=\"records\", lines=True)\nmdf = metrics_df.sort_values(\"iteration\")\nprint(mdf.head(10).T)\n\n# Plot loss\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"total_loss\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\n\nif \"validation_loss\" in mdf.columns:\n    mdf2 = mdf[~mdf[\"validation_loss\"].isna()]\n    ax.plot(mdf2[\"iteration\"], mdf2[\"validation_loss\"],\n            c=\"C1\", label=\"validation\")\n\nax.legend()\nax.set_title(\"Loss curve\")\nplt.show()\n\n# Plot Accuracy\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"fast_rcnn/cls_accuracy\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"fast_rcnn/cls_accuracy\"],\n        c=\"C0\", label=\"train\")\n\nax.legend()\nax.set_title(\"Accuracy curve\")\nplt.show()\n\n# Plot Bounding Box regressor loss\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"loss_box_reg\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"loss_box_reg\"], c=\"C0\", label=\"train\")\n\nax.legend()\nax.set_title(\"loss_box_reg\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:39:59.658315Z","iopub.execute_input":"2024-06-26T20:39:59.659353Z","iopub.status.idle":"2024-06-26T20:40:00.598252Z","shell.execute_reply.started":"2024-06-26T20:39:59.659315Z","shell.execute_reply":"2024-06-26T20:40:00.597345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ACCEPTANCE_THRESHOLD = 0.5  # for all categories\nprint(f\"#### MODEL: {inf_cfg.MODEL.WEIGHTS} FOR INFERENCE ####\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:40:13.726965Z","iopub.execute_input":"2024-06-26T20:40:13.727793Z","iopub.status.idle":"2024-06-26T20:40:13.732304Z","shell.execute_reply.started":"2024-06-26T20:40:13.727760Z","shell.execute_reply":"2024-06-26T20:40:13.731401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor = DefaultPredictor(inf_cfg)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:40:15.307845Z","iopub.execute_input":"2024-06-26T20:40:15.308610Z","iopub.status.idle":"2024-06-26T20:40:16.364116Z","shell.execute_reply.started":"2024-06-26T20:40:15.308580Z","shell.execute_reply":"2024-06-26T20:40:16.363114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom detectron2.utils.visualizer import Visualizer\n\nfig, ax = plt.subplots(4, 2, figsize=(20, 40))  # Updated subplot dimensions\nindices = [ax[i // 2][i % 2] for i in range(8)]  # Adjusted indices for 8 plots\n\n# Show some qualitative results by predicting on test set images\nNUM_TEST_SAMPLES = 8  # Updated number of test samples\nsamples = np.random.choice(dataset_dicts_valid, NUM_TEST_SAMPLES)\n\nfor i, sample in enumerate(samples):\n    img = cv2.imread(sample[\"file_name\"])\n    outputs = predictor(img)\n    visualizer = Visualizer(img, metadata=metadata_dicts_valid, scale=0.5)\n    visualizer = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    display_img = visualizer.get_image()[:, :, ::-1]\n    indices[i].grid(False)\n    indices[i].imshow(display_img)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:42:26.363290Z","iopub.execute_input":"2024-06-26T20:42:26.363698Z","iopub.status.idle":"2024-06-26T20:43:21.120127Z","shell.execute_reply.started":"2024-06-26T20:42:26.363666Z","shell.execute_reply":"2024-06-26T20:43:21.119148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom detectron2.utils.visualizer import Visualizer\n\nfig, ax = plt.subplots(4, 2, figsize=(20, 40))  # Updated subplot dimensions\nindices = [ax[i // 2][i % 2] for i in range(8)]  # Adjusted indices for 8 plots\n\n# Show some qualitative results by predicting on test set images\nNUM_TEST_SAMPLES = 8  # Updated number of test samples\nsamples = np.random.choice(dataset_dicts_valid, NUM_TEST_SAMPLES)\n\nfor i, sample in enumerate(samples):\n    img = cv2.imread(sample[\"file_name\"])\n    outputs = predictor(img)\n    visualizer = Visualizer(img, metadata=metadata_dicts_valid, scale=0.5)\n    visualizer = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    display_img = visualizer.get_image()[:, :, ::-1]\n    indices[i].grid(False)\n    indices[i].imshow(display_img)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nresults = inference_on_dataset(\n    evaluation_model, test_loader, evaluator=evaluator\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:44:39.387267Z","iopub.execute_input":"2024-06-26T20:44:39.387642Z","iopub.status.idle":"2024-06-26T20:52:13.446754Z","shell.execute_reply.started":"2024-06-26T20:44:39.387613Z","shell.execute_reply":"2024-06-26T20:52:13.445708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r /kaggle/working/output1.zip /kaggle/working/output\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:55:33.677988Z","iopub.execute_input":"2024-06-26T20:55:33.678948Z","iopub.status.idle":"2024-06-26T20:55:53.710348Z","shell.execute_reply.started":"2024-06-26T20:55:33.678904Z","shell.execute_reply":"2024-06-26T20:55:53.709201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/output/model_0019999.pth /kaggle/working/output/model_0029999.pth /kaggle/working/output/model_0009999.pth","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:54:27.454476Z","iopub.execute_input":"2024-06-26T20:54:27.455218Z","iopub.status.idle":"2024-06-26T20:54:28.667106Z","shell.execute_reply.started":"2024-06-26T20:54:27.455183Z","shell.execute_reply":"2024-06-26T20:54:28.665789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}